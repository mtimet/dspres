{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Table of Contents\n",
    "[1.Stochastic Gradient Descent](#sgd)\n",
    "\n",
    "[2.Gaussian Naive Bayes](#gnb)\n",
    "\n",
    "[3.Logistic Regresstion](#lr)\n",
    "\n",
    "[4.Bernoulli Naive Bayes](#bnb)\n",
    "\n",
    "[5.Meta Classifier](#meta_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble.voting_classifier import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \".\\\\data\"\n",
    "\n",
    "TRAINING_FILE = os.path.join(DATA_DIR, \"train.csv\")\n",
    "TEST_FILE = os.path.join(DATA_DIR, \"test.csv\")\n",
    "SUBMISSION_FILE = os.path.join(DATA_DIR, \"sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SFCrimesUtils(object):\n",
    "    @staticmethod\n",
    "    def get_df(fileName):\n",
    "        df = pd.read_csv(fileName,parse_dates=[\"Dates\"])\n",
    "        df[\"year\"] = df[\"Dates\"].dt.year\n",
    "        df[\"month\"] = df[\"Dates\"].dt.month\n",
    "        df[\"day\"] = df[\"Dates\"].dt.day\n",
    "        df[\"hour\"] = df[\"Dates\"].dt.hour\n",
    "        df[\"minute\"] = df[\"Dates\"].dt.minute\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def format_df(df):\n",
    "        df_train = pd.get_dummies(df[[\"DayOfWeek\"]])\n",
    "        df_train[\"hour\"] = df[\"hour\"]\n",
    "        if 'Category' in df.columns:\n",
    "            df_train[\"Category\"] = df[\"Category\"]\n",
    "        df_train[\"X\"] = df[\"X\"]\n",
    "        df_train[\"Y\"] = df[\"Y\"]\n",
    "\n",
    "        return df_train\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_train_test_data(df, size=0, rdm_state=0):\n",
    "        Y = df.Category.values\n",
    "        df_train = df.drop(labels=\"Category\", axis=1)\n",
    "        X = df_train[df_train.columns.values].values\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=size,random_state=rdm_state)\n",
    "        return (X_train, X_test, Y_train, Y_test)\n",
    "    \n",
    "    @staticmethod\n",
    "    def scale_data(X, sc=None, fit=True):\n",
    "        if sc is None:\n",
    "            sc = StandardScaler()\n",
    "        if fit==True:\n",
    "            sc.fit(X)\n",
    "        return sc.transform(X),sc\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_csv(csv_target_name, csv_template_name, clf, Y_Pred):\n",
    "        df_sub = pd.read_csv(csv_template_name, index_col=0)\n",
    "        columns = df_sub.columns.values\n",
    "        if False in np.equal(columns, clf.classes_):\n",
    "            print(\"columns from submission %s different from prediction %s\",columns,clf.classes_)\n",
    "            return\n",
    "        for i in df_sub.index.values:\n",
    "            df_sub.iloc[i] = Y_Pred[i]        \n",
    "        df_sub.to_csv(csv_target_name,compression=\"gzip\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def predict(clf, test_file_name, scaler):\n",
    "        df_test = SFCrimesUtils.get_df(test_file_name)\n",
    "        df_test = SFCrimesUtils.format_df(df_test)\n",
    "        X_test = df_test[df_test.columns.values].values\n",
    "        if not scaler is None:\n",
    "            X_test, sc = SFCrimesUtils.scale_data(X_test,scaler,fit=False)\n",
    "            return clf.predict_proba(X_test)  \n",
    "        return clf.predict_proba(X_test)    \n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_conf_matrix(Y_test, Y_pred):\n",
    "        labels = np.unique(Y_test)\n",
    "        cm = confusion_matrix(Y_test, Y_pred, labels)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(labels))\n",
    "        plt.xticks(tick_marks, labels, rotation=90)\n",
    "        plt.yticks(tick_marks, labels)\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = SFCrimesUtils.get_df(TRAINING_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = SFCrimesUtils.format_df(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 548 ms\n"
     ]
    }
   ],
   "source": [
    "TEST_RATIO = 0\n",
    "%time X_train , X_test, Y_train, Y_test = SFCrimesUtils.get_train_test_data(train,TEST_RATIO, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sgd'></a>\n",
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd  = Pipeline([\n",
    "                    ('scl', StandardScaler()),\n",
    "                    ('clf', SGDClassifier(loss=\"log\", n_iter=5))\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%time scores_sgd = cross_val_score(estimator=sgd, X=X_train, y=Y_train, cv=3, scoring='log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES [-2.71303367 -2.79768186 -2.84409673]\n",
      "MEAN -2.784937 / STD: 0.054260\n"
     ]
    }
   ],
   "source": [
    "print(\"SCORES %s\"% scores_sgd)\n",
    "print(\"MEAN %f / STD: %f\" % (np.mean(scores_sgd) ,np.std(scores_sgd)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gnb'></a>\n",
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gnb = Pipeline([\n",
    "                    ('scl', StandardScaler()),\n",
    "                    ('clf', GaussianNB())\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 46.4 s\n"
     ]
    }
   ],
   "source": [
    "%time scores_gnb = cross_val_score(estimator= gnb, X=X_train, y=Y_train, cv=3, scoring='log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES [-16.40102654 -13.27895076 -15.60691481]\n",
      "MEAN -15.095631 / STD: 1.324864\n"
     ]
    }
   ],
   "source": [
    "print(\"SCORES %s\"% scores_gnb)\n",
    "print(\"MEAN %f / STD: %f\" % (np.mean(scores_gnb) ,np.std(scores_gnb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lr'></a>\n",
    "# Logistic Regresstion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = Pipeline([\n",
    "                    ('scl', StandardScaler()),\n",
    "                    ('clf', LogisticRegression())\n",
    "             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 36s\n"
     ]
    }
   ],
   "source": [
    "%time scores_lr = cross_val_score(estimator= lr, X=X_train, y=Y_train, cv=3, scoring='log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES [-2.65541547 -2.65497172 -2.65567417]\n",
      "MEAN -2.655354 / STD: 0.000290\n"
     ]
    }
   ],
   "source": [
    "print(\"SCORES %s\"% scores_lr)\n",
    "print(\"MEAN %f / STD: %f\" % (np.mean(scores_lr) ,np.std(scores_lr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bnb'></a>\n",
    "# Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bnb  = Pipeline([\n",
    "                    ('scl', StandardScaler()),\n",
    "                    ('clf', BernoulliNB())\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 43.8 s\n"
     ]
    }
   ],
   "source": [
    "%time scores_bnb = cross_val_score(estimator= bnb, X=X_train, y=Y_train, cv=3, scoring='log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES [-2.63956975 -2.63966411 -2.63930682]\n",
      "MEAN -2.639514 / STD: 0.000151\n"
     ]
    }
   ],
   "source": [
    "print(\"SCORES %s\"% scores_bnb)\n",
    "print(\"MEAN %f / STD: %f\" % (np.mean(scores_bnb) ,np.std(scores_bnb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='meta_classifier'></a>\n",
    "# Meta Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meta_clf = VotingClassifier(estimators = [('lr', lr), ('sgd',sgd), ('bnb',bnb), \n",
    "                           (\"rfc\", RandomForestClassifier(min_samples_split=2, n_estimators = 10, criterion=\"entropy\", max_depth=5))],\n",
    "                            voting=\"soft\", weights=[0.25, 0.25, 0.25,0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time scores_meta = cross_val_score(estimator= meta_clf, X=X_train, y=Y_train, cv=3, scoring='log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"SCORES %s\"% scores_meta)\n",
    "print(\"MEAN %f / STD: %f\" % (np.mean(scores_meta) ,np.std(scores_meta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time Y_pred_kaggle = SFCrimesUtils.predict(meta_clf, TEST_FILE, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGET_CSV_NAME = os.path.join(DATA_DIR, \"submission_meta_clf.csv\")\n",
    "%time SFCrimesUtils.generate_csv(TARGET_CSV_NAME, SUBMISSION_FILE, meta_clf, Y_pred_kaggle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
