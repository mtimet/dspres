{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Table of Contents\n",
    "[1.Stochastic Gradient Descent](#sgd)\n",
    "\n",
    "[2.Gaussian Naive Bayes](#gnb)\n",
    "\n",
    "[3.Logistic Regresstion](#lr)\n",
    "\n",
    "[4.Bernoulli Naive Bayes](#bnb)\n",
    "\n",
    "[5.Hyper Params](#hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble.voting_classifier import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \".\\\\data\"\n",
    "\n",
    "TRAINING_FILE = os.path.join(DATA_DIR, \"train.csv\")\n",
    "TEST_FILE = os.path.join(DATA_DIR, \"test.csv\")\n",
    "SUBMISSION_FILE = os.path.join(DATA_DIR, \"sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SFCrimesUtils(object):\n",
    "    @staticmethod\n",
    "    def get_df(fileName):\n",
    "        df = pd.read_csv(fileName,parse_dates=[\"Dates\"])\n",
    "        df[\"year\"] = df[\"Dates\"].dt.year\n",
    "        df[\"month\"] = df[\"Dates\"].dt.month\n",
    "        df[\"day\"] = df[\"Dates\"].dt.day\n",
    "        df[\"hour\"] = df[\"Dates\"].dt.hour\n",
    "        df[\"minute\"] = df[\"Dates\"].dt.minute\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def format_df(df):\n",
    "        df_train = pd.get_dummies(df[[\"DayOfWeek\"]])\n",
    "        df_train[\"hour\"] = df[\"hour\"]\n",
    "        if 'Category' in df.columns:\n",
    "            df_train[\"Category\"] = df[\"Category\"]\n",
    "        df_train[\"X\"] = df[\"X\"]\n",
    "        df_train[\"Y\"] = df[\"Y\"]\n",
    "\n",
    "        return df_train\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_train_test_data(df, size=0, rdm_state=0):\n",
    "        Y = df.Category.values\n",
    "        df_train = df.drop(labels=\"Category\", axis=1)\n",
    "        X = df_train[df_train.columns.values].values\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=size,random_state=rdm_state)\n",
    "        return (X_train, X_test, Y_train, Y_test)\n",
    "    \n",
    "    @staticmethod\n",
    "    def scale_data(X, sc=None, fit=True):\n",
    "        if sc is None:\n",
    "            sc = StandardScaler()\n",
    "        if fit==True:\n",
    "            sc.fit(X)\n",
    "        return sc.transform(X),sc\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_csv(csv_target_name, csv_template_name, clf, Y_Pred):\n",
    "        df_sub = pd.read_csv(csv_template_name, index_col=0)\n",
    "        columns = df_sub.columns.values\n",
    "        if False in np.equal(columns, clf.classes_):\n",
    "            print(\"columns from submission %s different from prediction %s\",columns,clf.classes_)\n",
    "            return\n",
    "        for i in df_sub.index.values:\n",
    "            df_sub.iloc[i] = Y_Pred[i]        \n",
    "        df_sub.to_csv(csv_target_name)\n",
    "    \n",
    "    @staticmethod\n",
    "    def predict(clf, test_file_name, scaler):\n",
    "        df_test = SFCrimesUtils.get_df(test_file_name)\n",
    "        df_test = SFCrimesUtils.format_df(df_test)\n",
    "        X_test = df_test[df_test.columns.values].values\n",
    "        if not scaler is None:\n",
    "            X_test, sc = SFCrimesUtils.scale_data(X_test,scaler,fit=False)\n",
    "            return clf.predict_proba(X_test)  \n",
    "        return clf.predict_proba(X_test)    \n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_conf_matrix(Y_test, Y_pred):\n",
    "        labels = np.unique(Y_test)\n",
    "        cm = confusion_matrix(Y_test, Y_pred, labels)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(labels))\n",
    "        plt.xticks(tick_marks, labels, rotation=90)\n",
    "        plt.yticks(tick_marks, labels)\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = SFCrimesUtils.get_df(TRAINING_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = SFCrimesUtils.format_df(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 562 ms\n"
     ]
    }
   ],
   "source": [
    "TEST_RATIO = 0\n",
    "%time X_train , X_test, Y_train, Y_test = SFCrimesUtils.get_train_test_data(train,TEST_RATIO, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sgd'></a>\n",
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd  = Pipeline([\n",
    "                    ('scl', StandardScaler()),\n",
    "                    ('clf', SGDClassifier(loss=\"log\", n_iter=5))\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%time scores_sgd = cross_val_score(estimator=sgd, X=X_train, y=Y_train, cv=3, scoring='log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES [-2.73088742 -2.79413319 -2.72143317]\n",
      "MEAN -2.748818 / STD: 0.032274\n"
     ]
    }
   ],
   "source": [
    "print(\"SCORES %s\"% scores_sgd)\n",
    "print(\"MEAN %f / STD: %f\" % (np.mean(scores_sgd) ,np.std(scores_sgd)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gnb'></a>\n",
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gnb = Pipeline([\n",
    "                    ('scl', StandardScaler()),\n",
    "                    ('clf', GaussianNB())\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.6 s\n"
     ]
    }
   ],
   "source": [
    "%time scores_gnb = cross_val_score(estimator= gnb, X=X_train, y=Y_train, cv=3, scoring='log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES [-16.40102654 -13.27895076 -15.60691481]\n",
      "MEAN -15.095631 / STD: 1.324864\n"
     ]
    }
   ],
   "source": [
    "print(\"SCORES %s\"% scores_gnb)\n",
    "print(\"MEAN %f / STD: %f\" % (np.mean(scores_gnb) ,np.std(scores_gnb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lr'></a>\n",
    "# Logistic Regresstion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = Pipeline([\n",
    "                    ('scl', StandardScaler()),\n",
    "                    ('clf', LogisticRegression())\n",
    "             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 8s\n"
     ]
    }
   ],
   "source": [
    "%time scores_lr = cross_val_score(estimator= lr, X=X_train, y=Y_train, cv=3, scoring='log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES [-2.65541547 -2.65497172 -2.65567417]\n",
      "MEAN -2.655354 / STD: 0.000290\n"
     ]
    }
   ],
   "source": [
    "print(\"SCORES %s\"% scores_lr)\n",
    "print(\"MEAN %f / STD: %f\" % (np.mean(scores_lr) ,np.std(scores_lr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bnb'></a>\n",
    "# Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bnb  = Pipeline([\n",
    "                    ('scl', StandardScaler()),\n",
    "                    ('clf', BernoulliNB())\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30.7 s\n"
     ]
    }
   ],
   "source": [
    "%time scores_bnb = cross_val_score(estimator= bnb, X=X_train, y=Y_train, cv=3, scoring='log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES [-2.63956975 -2.63966411 -2.63930682]\n",
      "MEAN -2.639514 / STD: 0.000151\n"
     ]
    }
   ],
   "source": [
    "print(\"SCORES %s\"% scores_bnb)\n",
    "print(\"MEAN %f / STD: %f\" % (np.mean(scores_bnb) ,np.std(scores_bnb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hyper_params'></a>\n",
    "# Hyper Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = [\n",
    "               {\n",
    "                'C'      : [0.001, 0.01, 0.1, 1]\n",
    "               }\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=LogisticRegression(),\n",
    "                  param_grid=params,\n",
    "                  scoring=\"log_loss\",\n",
    "                  cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [0.001, 0.01, 0.1, 1]}], pre_dispatch='2*n_jobs',\n",
       "       refit=True, scoring='log_loss', verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time gs.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best score %s', -2.6645798095558706)\n",
      "('Best params %s', {'C': 1})\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score %s\",gs.best_score_)\n",
    "print(\"Best params %s\",gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 52s\n"
     ]
    }
   ],
   "source": [
    "%time scores_best_estimator = cross_val_score(estimator=gs.best_estimator_, X=X_train, y=Y_train, cv=3, scoring='log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES [-2.66460594 -2.66399112 -2.66422581]\n",
      "MEAN -2.664274 / STD: 0.000253\n"
     ]
    }
   ],
   "source": [
    "print(\"SCORES %s\"% scores_best_estimator)\n",
    "print(\"MEAN %f / STD: %f\" % (np.mean(scores_best_estimator) ,np.std(scores_best_estimator)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.19 s\n"
     ]
    }
   ],
   "source": [
    "%time Y_pred_kaggle = SFCrimesUtils.predict(gs.best_estimator_, TEST_FILE, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.12876722e-03,   8.62255637e-02,   8.42608254e-05, ...,\n",
       "          8.51252044e-02,   4.22392191e-02,   1.16215695e-02],\n",
       "       [  1.12961242e-03,   8.62146138e-02,   8.42779857e-05, ...,\n",
       "          8.51200608e-02,   4.22359904e-02,   1.16345891e-02],\n",
       "       [  9.19583009e-04,   8.87519043e-02,   8.66870086e-05, ...,\n",
       "          8.75852077e-02,   4.35763154e-02,   8.01535142e-03],\n",
       "       ..., \n",
       "       [  3.48298354e-03,   9.14697084e-02,   1.09085277e-03, ...,\n",
       "          3.26441121e-02,   5.26651476e-02,   1.37403327e-02],\n",
       "       [  2.95866465e-03,   9.61491588e-02,   1.15003096e-03, ...,\n",
       "          3.43250412e-02,   5.55068728e-02,   1.00039005e-02],\n",
       "       [  3.38352619e-03,   9.25144087e-02,   1.10140242e-03, ...,\n",
       "          3.30011890e-02,   5.32720718e-02,   1.29879318e-02]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 12s\n"
     ]
    }
   ],
   "source": [
    "TARGET_CSV_NAME = os.path.join(DATA_DIR, \"submission_best_model_with_hyper_params.csv\")\n",
    "%time SFCrimesUtils.generate_csv(TARGET_CSV_NAME, SUBMISSION_FILE, gs.best_estimator_, Y_pred_kaggle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
