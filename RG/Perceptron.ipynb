{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GRANVILLE\\Anaconda2\\Lib\\site-packages\\IPython\\kernel\\__init__.py:13: ShimWarning: The `IPython.kernel` package has been deprecated. You should import from ipykernel or jupyter_client instead.\n",
      "  \"You should import from ipykernel or jupyter_client instead.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.cross_validation import train_test_split\n",
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \".\\\\data\"\n",
    "SUBMISSION_DIR = \".\\\\submission\"\n",
    "TRAINING_FILE_NAME = \"train.csv\"\n",
    "TEST_FILE_NAME = \"test.csv\"\n",
    "SUBMISSION_FILE_NAME = \"sampleSubmission.csv\"\n",
    "TRAINING_FILE_FULL_NAME = os.path.join(DATA_DIR, TRAINING_FILE_NAME)\n",
    "TEST_FILE_FULL_NAME = os.path.join(DATA_DIR, TEST_FILE_NAME)\n",
    "SUBMISSION_FILE_FULL_NAME = os.path.join(DATA_DIR, SUBMISSION_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Processor(object):\n",
    "    @staticmethod\n",
    "    def get_df(fileName):\n",
    "        df = pd.read_csv(fileName,parse_dates=[\"Dates\"])\n",
    "        df[\"year\"] = df[\"Dates\"].dt.year\n",
    "        df[\"month\"] = df[\"Dates\"].dt.month\n",
    "        df[\"day\"] = df[\"Dates\"].dt.day\n",
    "        df[\"hour\"] = df[\"Dates\"].dt.hour\n",
    "        df[\"minute\"] = df[\"Dates\"].dt.minute\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def format_df(df):\n",
    "        df_train = pd.get_dummies(df[[\"DayOfWeek\"]])\n",
    "        df_train[\"year\"] = df[\"year\"]\n",
    "        df_train[\"month\"] = df[\"month\"]\n",
    "        df_train[\"hour\"] = df[\"hour\"]\n",
    "        df_train[\"minute\"] = df[\"minute\"]\n",
    "        if 'Category' in df.columns:\n",
    "            df_train[\"Category\"] = df[\"Category\"]\n",
    "        df_train[\"X\"] = df[\"X\"]\n",
    "        df_train[\"Y\"] = df[\"Y\"]\n",
    "\n",
    "        return df_train\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_train_test_data(df, size=0, rdm_state=0):\n",
    "        Y = df.Category.values\n",
    "        df_train = df.drop(labels=\"Category\", axis=1)\n",
    "        X = df_train[df_train.columns.values].values\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=size,random_state=rdm_state)\n",
    "        return (X_train, X_test, Y_train, Y_test)\n",
    "    \n",
    "    @staticmethod\n",
    "    def scale_data(X, sc=None, fit=True):\n",
    "        if sc is None:\n",
    "            sc = StandardScaler()\n",
    "        if fit==True:\n",
    "            sc.fit(X)\n",
    "        return sc.transform(X),sc\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_csv(csv_target_name, csv_template_name, Y):\n",
    "        df_sub = pd.read_csv(csv_template_name, index_col=0)\n",
    "        columns = df_sub.columns.values.tolist()\n",
    "        for i in df_sub.index.values:\n",
    "            v = Y[i]\n",
    "            index = columns.index(v)\n",
    "            values = np.zeros(len(columns))\n",
    "            values[index] = 1\n",
    "            df_sub.iloc[i] = values\n",
    "        \n",
    "        df_sub.to_csv(csv_target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 946 ms\n",
      "Wall time: 514 ms\n",
      "Wall time: 169 ms\n",
      "[[-0.42387962 -0.40090714 -0.41085416 ...,  2.08901178  0.75868254\n",
      "  -0.07872587]\n",
      " [-0.42387962 -0.40090714 -0.41085416 ...,  1.6587864   1.02437787\n",
      "  -0.08445725]\n",
      " [-0.42387962 -0.40090714 -0.41085416 ...,  1.60500822 -0.11153535\n",
      "   0.04638317]\n",
      " ..., \n",
      " [-0.42387962 -0.40090714 -0.41085416 ..., -1.03012229 -0.75120462\n",
      "  -0.12901384]\n",
      " [-0.42387962 -0.40090714 -0.41085416 ..., -1.03012229  1.16040026\n",
      "  -0.06903375]\n",
      " [-0.42387962 -0.40090714 -0.41085416 ..., -1.03012229 -2.21052862\n",
      "  -0.08113616]]\n",
      "[[ 2.35916039 -0.40090714 -0.41085416 ...,  0.52944475  1.05942836\n",
      "  -0.03465491]\n",
      " [-0.42387962 -0.40090714 -0.41085416 ...,  0.52944475 -0.09726921\n",
      "  -0.02104947]\n",
      " [-0.42387962 -0.40090714 -0.41085416 ...,  0.69077927  0.25636805\n",
      "  -0.05181756]\n",
      " ..., \n",
      " [-0.42387962 -0.40090714 -0.41085416 ..., -1.08390046  0.36316474\n",
      "   0.02633583]\n",
      " [-0.42387962 -0.40090714 -0.41085416 ..., -0.00833699  0.5064429\n",
      "   0.03402212]\n",
      " [-0.42387962 -0.40090714  2.43395369 ...,  0.26055388  1.19191058\n",
      "  -0.11345516]]\n"
     ]
    }
   ],
   "source": [
    "df_train = Processor.get_df(TRAINING_FILE_FULL_NAME)\n",
    "df_train = Processor.format_df(df_train)\n",
    "%time X_train , X_test, Y_train, Y_test = Processor.get_train_test_data(df_train,0,0)\n",
    "%time X_train_std, sc = Processor.scale_data(X_train, fit=True)\n",
    "\n",
    "df_test = Processor.get_df(TEST_FILE_FULL_NAME)\n",
    "df_test = Processor.format_df(df_test)\n",
    "X_test = df_test[df_test.columns.values].values\n",
    "%time X_test_std, sc = Processor.scale_data(X_test,sc,fit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I Basic Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, eta0=0.1, fit_intercept=True,\n",
       "      n_iter=40, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
       "      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppn = Perceptron(n_iter=40, eta0=0.1, random_state=0)\n",
    "%time ppn.fit(X_train_std, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred = ppn.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 7s\n"
     ]
    }
   ],
   "source": [
    "TARGET_CSV_NAME = os.path.join(SUBMISSION_DIR, \"submission.csv\")\n",
    "%time Processor.generate_csv(TARGET_CSV_NAME, SUBMISSION_FILE_FULL_NAME, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sub =pd.read_csv(SUBMISSION_FILE_FULL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II PERCEPTRON WITH ETA = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 39s\n",
      "Wall time: 5min 9s\n"
     ]
    }
   ],
   "source": [
    "ppnSmallEta = Perceptron(n_iter=40, eta0=0.001, random_state=0)\n",
    "%time ppnSmallEta.fit(X_train_std, Y_train)\n",
    "Y_pred = ppnSmallEta.predict(X_test_std)\n",
    "TARGET_CSV_NAME = os.path.join(SUBMISSION_DIR, \"submission_eta_0_001.csv\")\n",
    "%time Processor.generate_csv(TARGET_CSV_NAME, SUBMISSION_FILE_FULL_NAME, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II PERCEPTRON WITHOUT SHUFFLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppn_no_shuffle = Perceptron(n_iter=40, eta0=0.1, random_state=0, shuffle=False)\n",
    "%time ppn_no_shuffle.fit(X_train_std, Y_train)\n",
    "Y_pred = ppn_no_shuffle.predict(X_test_std)\n",
    "TARGET_CSV_NAME = os.path.join(SUBMISSION_DIR, \"submission_no_shuffle.csv\")\n",
    "%time Processor.generate_csv(TARGET_CSV_NAME, SUBMISSION_FILE_FULL_NAME, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III PERCEPTRON WITH L1 REGULARIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppn_L1= Perceptron(n_iter=40, eta0=0.1, random_state=0, penalty=\"l1\")\n",
    "%time ppn_L1.fit(X_train_std, Y_train)\n",
    "Y_pred = ppn_L1.predict(X_test_std)\n",
    "TARGET_CSV_NAME = os.path.join(SUBMISSION_DIR, \"submission_no_shuffle.csv\")\n",
    "%time Processor.generate_csv(TARGET_CSV_NAME, SUBMISSION_FILE_FULL_NAME, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppn_L2= Perceptron(n_iter=40, eta0=0.1, random_state=0, penalty=\"l2\")\n",
    "%time ppn_L1.fit(X_train_std, Y_train)\n",
    "Y_pred = ppn_L1.predict(X_test_std)\n",
    "TARGET_CSV_NAME = os.path.join(SUBMISSION_DIR, \"submission_no_shuffle.csv\")\n",
    "%time Processor.generate_csv(TARGET_CSV_NAME, SUBMISSION_FILE_FULL_NAME, Y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
